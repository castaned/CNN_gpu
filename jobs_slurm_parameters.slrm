#!/bin/sh

#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --job-name=tensorflow-gpu-array
#SBATCH --time=1:00:00
#SBATCH --partition=ibtesla
#SBATCH --gres=gpu:1
#SBATCH --export=NONE
#SBATCH --mem-per-cpu=3200
#SBATCH --output=array_%A_%a.out
#SBATCH --error=array_%A_%a.err
#SBATCH --array=1-4

# Print the task id.
echo "My SLURM_ARRAY_TASK_ID: " $SLURM_ARRAY_TASK_ID

#Directorio scratch en disco local
#SCRATCH_DIR=/scratch/$USER/$SLURM_JOBID

pwd
module load miniconda/3
eval "$(conda shell.bash hook)"
conda activate tf24
conda info --envs
module load cuda/11.0 
export HDF5_USE_FILE_LOCKING='FALSE'


# configuracion inicial
if [ $SLURM_ARRAY_TASK_ID == 1 ]; then
    python classification_parameters.py adam 0
fi

# configuracion inicial + variacion optimizer a "SGD"
if [ $SLURM_ARRAY_TASK_ID == 2 ]; then
    python classification_parameters.py sgd 0
fi

# configuracion inicial + variacion optimizer a "ADAMAX"
if [ $SLURM_ARRAY_TASK_ID == 3 ]; then
    python classification_parameters.py adamax 0
fi

# configuracion inicial + variacion capa adicional
if [ $SLURM_ARRAY_TASK_ID == 4 ]; then 
    python classification_parameters.py adam 1
fi    


